"""
Natural language explanation generator.

Converts model attributions into human-readable explanations.
"""

from typing import Dict, List, Optional

import numpy as np


DISCLAIMER = (
    "Generated by a research model on deidentified or synthetic data. "
    "Not for clinical use."
)


def format_risk_level(risk_score: float) -> str:
    """
    Convert risk score to categorical label.

    Args:
        risk_score: Risk probability [0-1]

    Returns:
        Risk level string
    """
    if risk_score < 0.3:
        return "Low"
    elif risk_score < 0.7:
        return "Medium"
    else:
        return "High"


def format_feature_value(feature_name: str, value: float) -> str:
    """
    Format feature value for display.

    Args:
        feature_name: Name of the feature
        value: Feature value

    Returns:
        Formatted string
    """
    # Parse feature name
    parts = feature_name.split("_")

    if "vital" in feature_name or "lab" in feature_name:
        # Extract measurement name
        if len(parts) > 1:
            measure = " ".join(parts[1:])
            return f"{measure}: {value:.1f}"
    elif "med" in feature_name:
        if "given" in feature_name:
            return f"{parts[1]} administered"
        else:
            return f"{parts[1]}"

    return f"{feature_name}: {value:.2f}"


def generate_logistic_explanation(
    risk_score: float,
    attributions: List[Dict],
    task: str = "readmission",
) -> str:
    """
    Generate explanation for logistic regression prediction.

    Args:
        risk_score: Predicted risk score
        attributions: List of feature attributions
        task: Prediction task

    Returns:
        Human-readable explanation
    """
    risk_level = format_risk_level(risk_score)

    # Task-specific intro
    if task == "readmission":
        outcome = "30-day readmission"
    elif task == "icu_mortality":
        outcome = "48-hour ICU mortality"
    else:
        outcome = "adverse outcome"

    explanation = f"{risk_level} risk of {outcome} (score: {risk_score:.2f}).\n\n"

    # Key drivers
    if len(attributions) > 0:
        explanation += "Key contributing factors:\n"

        for i, attr in enumerate(attributions[:5], 1):
            feature = attr["feature"]
            value = attr["value"]
            contribution = attr["contribution"]

            direction = "increases" if contribution > 0 else "decreases"

            # Format based on feature type
            if "mean" in feature or "max" in feature or "min" in feature:
                parts = feature.rsplit("_", 1)
                measure = parts[0]
                stat = parts[1] if len(parts) > 1 else ""
                explanation += f"  {i}. {measure} ({stat}): {value:.1f} {direction} risk\n"
            elif "med" in feature:
                med_name = feature.replace("med_", "").replace("_given", "").replace("_count", "")
                if value > 0:
                    explanation += f"  {i}. {med_name} administered {direction} risk\n"
            elif "comorbidity" in feature:
                comorb_name = feature.replace("comorbidity_", "").upper()
                if value > 0:
                    explanation += f"  {i}. History of {comorb_name} {direction} risk\n"
            else:
                explanation += f"  {i}. {feature}: {value:.2f} {direction} risk\n"

    explanation += f"\n{DISCLAIMER}"

    return explanation


def generate_sequence_explanation(
    risk_score: float,
    important_events: List[Dict],
    task: str = "readmission",
    bin_hours: int = 4,
) -> str:
    """
    Generate explanation for sequence model prediction.

    Args:
        risk_score: Predicted risk score
        important_events: List of important events with timesteps
        task: Prediction task
        bin_hours: Hours per time bin

    Returns:
        Human-readable explanation
    """
    risk_level = format_risk_level(risk_score)

    # Task-specific intro
    if task == "readmission":
        outcome = "30-day readmission"
        window = "final 48 hours before discharge"
    elif task == "icu_mortality":
        outcome = "48-hour ICU mortality"
        window = "first 48 hours of ICU stay"
    else:
        outcome = "adverse outcome"
        window = "observation period"

    explanation = f"{risk_level} risk of {outcome} (score: {risk_score:.2f}).\n\n"

    # Temporal patterns
    if len(important_events) > 0:
        explanation += f"Key clinical signals during {window}:\n\n"

        for i, event in enumerate(important_events[:3], 1):
            timestep = event["timestep"]
            features = event["features"]

            # Convert timestep to time description
            start_hour = timestep * bin_hours
            end_hour = start_hour + bin_hours

            if end_hour <= 24:
                time_desc = f"hours {start_hour}-{end_hour}"
            else:
                time_desc = f"hours {start_hour}-{end_hour} ({start_hour//24}d {start_hour%24}h - {end_hour//24}d {end_hour%24}h)"

            explanation += f"  {i}. Time period {time_desc}:\n"

            for feature in features[:3]:
                feature_name = feature["feature"]
                feature_value = feature["value"]

                # Parse and format feature
                if "vital" in feature_name:
                    measure = feature_name.replace("vital_", "").replace("_", " ").title()
                    explanation += f"     - {measure}: {feature_value:.1f}\n"
                elif "lab" in feature_name:
                    measure = feature_name.replace("lab_", "").replace("_", " ").title()
                    explanation += f"     - {measure}: {feature_value:.1f}\n"
                elif "med" in feature_name:
                    med = feature_name.replace("med_", "").replace("_", " ").title()
                    if feature_value > 0:
                        explanation += f"     - {med} administered\n"

            explanation += "\n"

    explanation += f"{DISCLAIMER}"

    return explanation


def generate_contributing_events(
    important_events: List[Dict],
    task: str = "readmission",
    bin_hours: int = 4,
) -> List[Dict]:
    """
    Generate structured contributing events for API response.

    Args:
        important_events: List of important events from attribution
        task: Prediction task
        bin_hours: Hours per time bin

    Returns:
        List of contributing event dictionaries
    """
    contributing = []

    for event in important_events:
        timestep = event["timestep"]
        features = event.get("features", [])

        # Time calculation
        start_hour = timestep * bin_hours
        time_str = f"Hour {start_hour}-{start_hour + bin_hours}"

        for feature in features[:3]:
            feature_name = feature["feature"]
            feature_value = feature.get("value", 0.0)

            # Determine event type and code
            if "vital" in feature_name:
                event_type = "vital"
                code = feature_name.replace("vital_", "")
            elif "lab" in feature_name:
                event_type = "lab"
                code = feature_name.replace("lab_", "")
            elif "med" in feature_name:
                event_type = "medication"
                code = feature_name.replace("med_", "")
            else:
                event_type = "other"
                code = feature_name

            contributing.append(
                {
                    "time": time_str,
                    "type": event_type,
                    "code": code,
                    "value": float(feature_value) if feature_value else None,
                    "contribution_score": float(event.get("importance", 0.0)),
                }
            )

    return contributing


def explain_prediction(
    model_type: str,
    risk_score: float,
    task: str,
    attributions: Optional[List[Dict]] = None,
    important_events: Optional[List[Dict]] = None,
    bin_hours: int = 4,
) -> tuple[str, List[Dict]]:
    """
    Generate complete explanation for a prediction.

    Args:
        model_type: Type of model ('logistic', 'gru', 'transformer')
        risk_score: Predicted risk score
        task: Prediction task
        attributions: Feature attributions (for logistic)
        important_events: Important temporal events (for sequence models)
        bin_hours: Hours per time bin

    Returns:
        Tuple of (explanation text, contributing events list)
    """
    if model_type == "logistic":
        explanation = generate_logistic_explanation(risk_score, attributions or [], task)
        contributing = []
        if attributions:
            for attr in attributions[:5]:
                contributing.append(
                    {
                        "time": "overall",
                        "type": "feature",
                        "code": attr["feature"],
                        "value": attr.get("value"),
                        "contribution_score": abs(attr.get("contribution", 0.0)),
                    }
                )
    else:  # sequence models
        explanation = generate_sequence_explanation(
            risk_score, important_events or [], task, bin_hours
        )
        contributing = generate_contributing_events(
            important_events or [], task, bin_hours
        )

    return explanation, contributing
