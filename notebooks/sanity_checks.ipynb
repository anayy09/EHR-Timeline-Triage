{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from ehrtriage.config import DATA_DIR, MODELS_DIR, load_config\n",
    "from ehrtriage.synthetic_data import generate_synthetic_data\n",
    "from ehrtriage.cohort import build_readmission_cohort, build_icu_mortality_cohort\n",
    "from ehrtriage.features import build_snapshot_features\n",
    "from ehrtriage.schemas import Event, PatientTimeline\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de3c8f",
   "metadata": {},
   "source": [
    "## 1. Check Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26575736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate small synthetic dataset\n",
    "print(\"Generating synthetic data...\")\n",
    "patients, admissions, icu_stays, events = generate_synthetic_data(\n",
    "    n_patients=50,\n",
    "    random_seed=12345\n",
    ")\n",
    "\n",
    "# Validate outputs\n",
    "assert len(patients) == 50, \"Expected 50 patients\"\n",
    "assert len(admissions) > 0, \"Expected admissions\"\n",
    "assert len(events) > 0, \"Expected events\"\n",
    "\n",
    "# Check schema\n",
    "assert 'subject_id' in patients.columns\n",
    "assert 'age' in patients.columns\n",
    "assert 'gender' in patients.columns\n",
    "\n",
    "assert 'hadm_id' in admissions.columns\n",
    "assert 'admittime' in admissions.columns\n",
    "assert 'dischtime' in admissions.columns\n",
    "\n",
    "assert 'event_type' in events.columns\n",
    "assert 'event_code' in events.columns\n",
    "assert 'value' in events.columns\n",
    "\n",
    "print(\"✓ Synthetic data generation: PASSED\")\n",
    "print(f\"  - Patients: {len(patients)}\")\n",
    "print(f\"  - Admissions: {len(admissions)}\")\n",
    "print(f\"  - Events: {len(events)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34defccd",
   "metadata": {},
   "source": [
    "## 2. Check Cohort Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69992b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build readmission cohort\n",
    "print(\"\\nBuilding readmission cohort...\")\n",
    "readmission_cohort = build_readmission_cohort(admissions)\n",
    "\n",
    "assert len(readmission_cohort) > 0, \"Cohort should not be empty\"\n",
    "assert 'readmit_30d' in readmission_cohort.columns, \"Missing label column\"\n",
    "assert readmission_cohort['readmit_30d'].isin([0, 1]).all(), \"Labels should be 0 or 1\"\n",
    "\n",
    "print(\"✓ Readmission cohort building: PASSED\")\n",
    "print(f\"  - Cohort size: {len(readmission_cohort)}\")\n",
    "print(f\"  - Readmission rate: {readmission_cohort['readmit_30d'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce572a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ICU mortality cohort\n",
    "print(\"\\nBuilding ICU mortality cohort...\")\n",
    "icu_cohort = build_icu_mortality_cohort(icu_stays, patients)\n",
    "\n",
    "assert len(icu_cohort) > 0, \"Cohort should not be empty\"\n",
    "assert 'mortality_label' in icu_cohort.columns, \"Missing label column\"\n",
    "assert icu_cohort['mortality_label'].isin([0, 1]).all(), \"Labels should be 0 or 1\"\n",
    "\n",
    "print(\"✓ ICU mortality cohort building: PASSED\")\n",
    "print(f\"  - Cohort size: {len(icu_cohort)}\")\n",
    "print(f\"  - Mortality rate: {icu_cohort['mortality_label'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a6737",
   "metadata": {},
   "source": [
    "## 3. Check Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test snapshot feature building\n",
    "print(\"\\nTesting snapshot feature building...\")\n",
    "\n",
    "# Filter events for one admission\n",
    "sample_hadm = readmission_cohort.iloc[0]\n",
    "sample_events = events[\n",
    "    (events['hadm_id'] == sample_hadm['hadm_id']) &\n",
    "    (pd.to_datetime(events['charttime']) <= pd.to_datetime(sample_hadm['discharge_time']))\n",
    "]\n",
    "\n",
    "print(f\"Sample admission has {len(sample_events)} events\")\n",
    "\n",
    "# Build features for this admission\n",
    "config = load_config()\n",
    "sample_cohort = readmission_cohort.head(10)  # Use first 10 for testing\n",
    "\n",
    "try:\n",
    "    features_df = build_snapshot_features(\n",
    "        events_df=events,\n",
    "        cohort_df=sample_cohort,\n",
    "        config=config,\n",
    "        task='readmission'\n",
    "    )\n",
    "    \n",
    "    assert len(features_df) == len(sample_cohort), \"Feature rows should match cohort\"\n",
    "    assert features_df.shape[1] > 0, \"Should have features\"\n",
    "    assert not features_df.isnull().all().any(), \"No completely null columns\"\n",
    "    \n",
    "    print(\"✓ Snapshot feature building: PASSED\")\n",
    "    print(f\"  - Feature shape: {features_df.shape}\")\n",
    "    print(f\"  - Sample features: {list(features_df.columns[:5])}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Snapshot feature building: FAILED\")\n",
    "    print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40d03b",
   "metadata": {},
   "source": [
    "## 4. Check Sequence Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ehrtriage.sequence_builder import build_sequence_for_stay\n",
    "\n",
    "print(\"\\nTesting sequence building...\")\n",
    "\n",
    "# Build sequence for one admission\n",
    "try:\n",
    "    sequence, mask, times = build_sequence_for_stay(\n",
    "        stay_id=sample_hadm['hadm_id'],\n",
    "        events_df=events,\n",
    "        start_time=pd.to_datetime(sample_hadm['index_admit_time']),\n",
    "        end_time=pd.to_datetime(sample_hadm['discharge_time']),\n",
    "        config=config,\n",
    "        max_length=24  # 24 time bins\n",
    "    )\n",
    "    \n",
    "    assert sequence.shape[0] <= 24, \"Sequence length should not exceed max_length\"\n",
    "    assert sequence.shape[1] > 0, \"Should have feature dimensions\"\n",
    "    assert len(mask) == len(sequence), \"Mask length should match sequence\"\n",
    "    assert mask.sum() > 0, \"Should have at least some valid time bins\"\n",
    "    \n",
    "    print(\"✓ Sequence building: PASSED\")\n",
    "    print(f\"  - Sequence shape: {sequence.shape}\")\n",
    "    print(f\"  - Valid time bins: {mask.sum()} / {len(mask)}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Sequence building: FAILED\")\n",
    "    print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12941d",
   "metadata": {},
   "source": [
    "## 5. Check Model Loading and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ehrtriage.models.baselines import LogisticBaseline\n",
    "\n",
    "print(\"\\nTesting model loading and prediction...\")\n",
    "\n",
    "try:\n",
    "    model_dir = MODELS_DIR / \"artifacts\" / \"readmission\"\n",
    "    if (model_dir / \"logistic_model.pkl\").exists():\n",
    "        model = LogisticBaseline.load(model_dir, \"logistic\")\n",
    "        \n",
    "        # Make a prediction on dummy data\n",
    "        n_features = len(model.feature_names) if hasattr(model, 'feature_names') else 100\n",
    "        dummy_input = np.random.randn(1, n_features)\n",
    "        \n",
    "        proba = model.predict_proba(dummy_input)\n",
    "        \n",
    "        assert proba.shape == (1, 2), \"Prediction shape should be (1, 2)\"\n",
    "        assert np.isclose(proba.sum(), 1.0), \"Probabilities should sum to 1\"\n",
    "        assert (proba >= 0).all() and (proba <= 1).all(), \"Probabilities should be in [0, 1]\"\n",
    "        \n",
    "        print(\"✓ Model loading and prediction: PASSED\")\n",
    "        print(f\"  - Model type: Logistic Regression\")\n",
    "        print(f\"  - Prediction: {proba[0, 1]:.4f}\")\n",
    "    else:\n",
    "        print(\"⊘ Model not found. Run training first.\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Model loading: FAILED\")\n",
    "    print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28837d4b",
   "metadata": {},
   "source": [
    "## 6. Check Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTesting Pydantic schemas...\")\n",
    "\n",
    "# Test Event schema\n",
    "event = Event(\n",
    "    time=\"2024-01-01T12:00:00\",\n",
    "    type=\"vital\",\n",
    "    code=\"HR\",\n",
    "    value=80.0\n",
    ")\n",
    "assert event.type == \"vital\"\n",
    "assert event.value == 80.0\n",
    "\n",
    "# Test PatientTimeline schema\n",
    "timeline = PatientTimeline(\n",
    "    subject_id=\"TEST001\",\n",
    "    stay_id=\"ADM001\",\n",
    "    events=[\n",
    "        Event(time=\"2024-01-01T12:00:00\", type=\"vital\", code=\"HR\", value=80.0),\n",
    "        Event(time=\"2024-01-01T13:00:00\", type=\"lab\", code=\"CREATININE\", value=1.2),\n",
    "    ]\n",
    ")\n",
    "assert len(timeline.events) == 2\n",
    "assert timeline.subject_id == \"TEST001\"\n",
    "\n",
    "print(\"✓ Schema validation: PASSED\")\n",
    "print(f\"  - Event schema: OK\")\n",
    "print(f\"  - PatientTimeline schema: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59541b37",
   "metadata": {},
   "source": [
    "## 7. Check Explanation Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ehrtriage.explain.text_generator import generate_logistic_explanation\n",
    "\n",
    "print(\"\\nTesting explanation generation...\")\n",
    "\n",
    "# Mock attributions\n",
    "attributions = [\n",
    "    ('HR_mean', 0.15),\n",
    "    ('CREATININE_mean', 0.12),\n",
    "    ('BP_SYSTOLIC_min', -0.08),\n",
    "]\n",
    "\n",
    "explanation = generate_logistic_explanation(\n",
    "    risk_score=0.75,\n",
    "    task='readmission',\n",
    "    attributions=attributions\n",
    ")\n",
    "\n",
    "assert isinstance(explanation, str), \"Explanation should be a string\"\n",
    "assert len(explanation) > 0, \"Explanation should not be empty\"\n",
    "assert \"research\" in explanation.lower() or \"prototype\" in explanation.lower(), \"Should contain disclaimer\"\n",
    "\n",
    "print(\"✓ Explanation generation: PASSED\")\n",
    "print(f\"  - Explanation length: {len(explanation)} characters\")\n",
    "print(f\"  - Sample: {explanation[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b657c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "All sanity checks completed. Review results above for any failures.\n",
    "\n",
    "### Expected Status:\n",
    "- ✓ = Passed\n",
    "- ✗ = Failed\n",
    "- ⊘ = Skipped (e.g., models not trained yet)\n",
    "\n",
    "If any checks failed, review the error messages and ensure:\n",
    "1. Dependencies are installed correctly\n",
    "2. Data has been generated\n",
    "3. Models have been trained (if testing model-related checks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
